{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6b8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2facee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "card_text = pd.read_json('oracle-cards-20220819210331.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c91731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 69 unnecessary columns\n",
    "\n",
    "drop_cols = ['object', 'id', 'oracle_id', 'multiverse_ids', 'mtgo_id', 'mtgo_foil_id', 'tcgplayer_id','cardmarket_id', 'lang', \n",
    "             'released_at', 'uri', 'scryfall_uri', 'layout', 'highres_image', 'image_status', 'image_uris', 'colors',\n",
    "             'legalities', 'games', 'reserved', 'foil', 'nonfoil', 'finishes', 'oversized', 'promo', 'reprint', 'variation',\n",
    "             'set_id', 'set', 'set_uri', 'set_search_uri', 'scryfall_set_uri', 'rulings_uri', 'prints_search_uri',\n",
    "             'collector_number', 'digital', 'card_back_id', 'artist', 'artist_ids', 'illustration_id', 'border_color', 'frame',\n",
    "             'full_art', 'textless', 'booster', 'story_spotlight', 'prices', 'related_uris', 'security_stamp', 'preview',\n",
    "             'power', 'toughness', 'penny_rank', 'arena_id', 'watermark', 'produced_mana', 'all_parts', 'card_faces',\n",
    "             'frame_effects', 'tcgplayer_etched_id', 'promo_types', 'loyalty', 'life_modifier', 'hand_modifier',\n",
    "             'color_indicator', 'content_warning', 'cmc', 'keywords', 'flavor_text', 'edhrec_rank']\n",
    "\n",
    "card_text = card_text.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d61268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "\n",
    "# fill NaNs\n",
    "card_text['oracle_text'] = card_text['oracle_text'].fillna('None')\n",
    "\n",
    "# drop useless rows\n",
    "vangard_mask = ((card_text['set_type'] == 'vanguard') |\n",
    "                (card_text['type_line'] == 'Vanguard') |\n",
    "                (card_text['set_name'].str.contains('Vanguard')))\n",
    "card_text.drop(card_text[vangard_mask].index, inplace = True)\n",
    "card_text.drop(card_text[card_text['type_line'].str.contains('Emblem')].index, inplace = True)\n",
    "card_text.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# emliminate extraneous characters\n",
    "unwanted_text = \"[.,!?()•—\\\\:;|]\"\n",
    "card_text['oracle_text'] = card_text['oracle_text'].map(lambda x: re.sub(unwanted_text, '', x))\n",
    "\n",
    "# remove all references of a card's name from it's rules text\n",
    "card_text['Rules_Text'] = card_text[['name', 'oracle_text']].apply(lambda x: \n",
    "                                                                     x['oracle_text'].replace(x['name'], 'This_Card')\n",
    "                                                                     if x['name'] in x['oracle_text']\n",
    "                                                                     else x['oracle_text'],\n",
    "                                                                     axis = 1)\n",
    "\n",
    "# set rules_text to lower case\n",
    "card_text['Rules_Text'] = card_text['Rules_Text'].str.lower()\n",
    "\n",
    "# # create new dataframe with which to work\n",
    "# ct = card_text['Rules_Text'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04795ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize whitespace tokenizer\n",
    "# whitespace_tokenizer = RegexpTokenizer(\"\\s+\", gaps = True)\n",
    "\n",
    "# # make new column for whitespace tokenizer\n",
    "# ct['no_space_tokens'] = ct['Rules_Text'].apply(lambda x: whitespace_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c781162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load english library with spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# # set function to get spacy tokens\n",
    "# def spacy_on_list(x):\n",
    "#     spacy_list = [nlp(element) for element in x]\n",
    "#     return spacy_list\n",
    "\n",
    "# # make new column for spacy tokens\n",
    "# ct['spacy_tokens'] = ct['no_space_tokens'].apply(lambda x: spacy_on_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a224f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ct\n",
    "# with open('ct_df', 'wb') as f:\n",
    "#     pickle.dump(ct,f)\n",
    "    \n",
    "# load ct\n",
    "with open('ct_df', 'rb') as f:\n",
    "    ct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa5420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy fucntion to pass to custom_tfidf\n",
    "def dummy_function(doc):\n",
    "    return doc\n",
    "\n",
    "# # save spacy tokens as list\n",
    "# docs = ct['spacy_tokens'].to_list()\n",
    "\n",
    "# # save spacy tokens as series\n",
    "# doc_series = pd.Series(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f30925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set function to get lemmetized non-stop-words\n",
    "def lemmy_no_stop(x):\n",
    "    core_text = []\n",
    "    for tuple_ in x:\n",
    "        for token in tuple_:\n",
    "            core_text.append(token.lemma_)  \n",
    "    #core_text = [[token.lemma_ for token in tuple_ if token.is_stop == False] for tuple_ in x]  \n",
    "    core_text = [ele for ele in core_text if ele != []]\n",
    "    return core_text\n",
    "\n",
    "# apply fucntion to create new column in ct\n",
    "ct['core_text'] = ct['spacy_tokens'].apply(lambda x: lemmy_no_stop(x))\n",
    "\n",
    "# convert that column to a list\n",
    "core_docs = ct['core_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526d87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tfidf_2gram = TfidfVectorizer(analyzer='word', tokenizer=dummy_function,\n",
    "                                     preprocessor=dummy_function, token_pattern=None)\n",
    "CX_2gram = custom_tfidf_2gram.fit_transform(core_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722e53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26182, 4681)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CX_2gram = StandardScaler().fit_transform(CX_2gram)\n",
    "CX_2gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488da4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448770959907811"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 150)\n",
    "pca.fit(CX_2gram)\n",
    "# pca.explained_variance_ratio_\n",
    "\n",
    "def evr (array):\n",
    "    _sum = 0\n",
    "    for element in array:\n",
    "        _sum += element\n",
    "    return _sum\n",
    "\n",
    "evr(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5154488",
   "metadata": {},
   "outputs": [],
   "source": [
    "CX_2gram = pca.transform(CX_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e09c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "num_clusters = 20\n",
    "km = KMeans(n_clusters= num_clusters,\n",
    "            random_state=7,\n",
    "           n_init=10)\n",
    "km.fit(CX_2gram)\n",
    "km_df = km.transform(CX_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e6bd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Card:\tMerfolk Looter\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Merfolk Rogue\n",
      "Text:\t\t{T} Draw a card then discard a card\n",
      "************************************************************\n",
      "************************************************************\n",
      "Name:\t\tThought Courier\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tThe Harvester\n",
      "Mana Cost:\t\n",
      "Type:\t\tHero\n",
      "Text:\t\t{t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tRummaging Goblin\n",
      "Mana Cost:\t{2}{R}\n",
      "Type:\t\tCreature — Goblin Rogue\n",
      "Text:\t\t{t} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tLore Broker\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Human Rogue\n",
      "Text:\t\t{t} each player draws a card then discards a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tCephalid Looter\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Cephalid Rogue\n",
      "Text:\t\t{t} target player draws a card then discards a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tReckless Scholar\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} target player draws a card then discards a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tMad Prophet\n",
      "Mana Cost:\t{3}{R}\n",
      "Type:\t\tCreature — Human Shaman\n",
      "Text:\t\thaste, {t} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tSelhoff Entomber\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Zombie\n",
      "Text:\t\t{t} discard a creature card draw a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tUnburden\n",
      "Mana Cost:\t{1}{B}{B}\n",
      "Type:\t\tSorcery\n",
      "Text:\t\ttarget player discards two cards, cycling {2} {2} discard this card draw a card\n",
      "------------------------------------------------------------\n",
      "Name:\t\tDrowned Rusalka\n",
      "Mana Cost:\t{U}\n",
      "Type:\t\tCreature — Spirit\n",
      "Text:\t\t{u} sacrifice a creature discard a card then draw a card\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Local\\Temp/ipykernel_3652/359534552.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top10['Rules_Text'] = top10['Rules_Text'].str.replace('\\n', ', ')\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe for results\n",
    "\n",
    "# card_name = \"Kess, Dissident Mage\"\n",
    "card_name = \"Merfolk Looter\"\n",
    "\n",
    "index = card_text.index[card_text['name'] == card_name]\n",
    "distances = pairwise_distances(km_df[index].reshape(1,-1), km_df, metric='euclidean')\n",
    "\n",
    "results_df = card_text[['name', 'Rules_Text', 'color_identity', 'mana_cost', 'type_line', 'rarity', 'set_name',\n",
    "                                'set_type']]\n",
    "results_df.insert(loc = 0, column = 'distances', value = pd.Series(distances[0]))\n",
    "\n",
    "# Merge NMF DF with results_df:\n",
    "# results_df = initial_results_df.merge(nmf_2gram_df, left_index=True, right_index=True)\n",
    "\n",
    "# recommend the top 10 most similar instances to card of interest (excluding itself)\n",
    "\n",
    "top10 = results_df[results_df['name'] != card_name]\n",
    "top10['Rules_Text'] = top10['Rules_Text'].str.replace('\\n', ', ')\n",
    "card_text['oracle_text'] = card_text['oracle_text'].str.replace('\\n', ', ')\n",
    "top10 = top10.sort_values(by = 'distances', ascending = True).head(10).reset_index(drop=True)\n",
    "\n",
    "# output results\n",
    "print(f\"Chosen Card:\\t{card_text['name'].iloc[index[0]]}\")\n",
    "print(f\"Mana Cost:\\t{card_text['mana_cost'].iloc[index[0]]}\")\n",
    "print(f\"Type:\\t\\t{card_text['type_line'].iloc[index[0]]}\")\n",
    "print(f\"Text:\\t\\t{card_text['oracle_text'].iloc[index[0]]}\\n{'*'*60}\\n{'*'*60}\")\n",
    "for i in range(10):\n",
    "    print(f\"Name:\\t\\t{top10['name'].values[i]}\")\n",
    "    print(f\"Mana Cost:\\t{top10['mana_cost'].values[i]}\")\n",
    "    print(f\"Type:\\t\\t{top10['type_line'].values[i]}\")\n",
    "    print(f\"Text:\\t\\t{top10['Rules_Text'].values[i]}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af0d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Less than perfect matches for: Kess, Dissident Mage\n",
    "\n",
    "# Norika Yamazaki, the Poet\n",
    "# Waves of Aggression\n",
    "# Abandoned Sarcophagus\n",
    "# Dihada's Ploy\n",
    "\n",
    "# -------------\n",
    "\n",
    "# Horobi's Whisper\n",
    "# Cosmos Charger\n",
    "# Scourge of Nel Toth\n",
    "# Reconstruct History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "294a0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b30b3676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model among TFIDF, NMF, KMEANS, ADVANCED and turn that into a streamlit app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
