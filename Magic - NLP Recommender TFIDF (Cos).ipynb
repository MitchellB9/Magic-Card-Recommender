{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6b8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2facee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "card_text = pd.read_json('oracle-cards-20220819210331.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c91731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 69 unnecessary columns\n",
    "\n",
    "drop_cols = ['object', 'id', 'oracle_id', 'multiverse_ids', 'mtgo_id', 'mtgo_foil_id', 'tcgplayer_id','cardmarket_id', 'lang', \n",
    "             'released_at', 'uri', 'scryfall_uri', 'layout', 'highres_image', 'image_status', 'image_uris', 'colors',\n",
    "             'legalities', 'games', 'reserved', 'foil', 'nonfoil', 'finishes', 'oversized', 'promo', 'reprint', 'variation',\n",
    "             'set_id', 'set', 'set_uri', 'set_search_uri', 'scryfall_set_uri', 'rulings_uri', 'prints_search_uri',\n",
    "             'collector_number', 'digital', 'card_back_id', 'artist', 'artist_ids', 'illustration_id', 'border_color', 'frame',\n",
    "             'full_art', 'textless', 'booster', 'story_spotlight', 'prices', 'related_uris', 'security_stamp', 'preview',\n",
    "             'power', 'toughness', 'penny_rank', 'arena_id', 'watermark', 'produced_mana', 'all_parts', 'card_faces',\n",
    "             'frame_effects', 'tcgplayer_etched_id', 'promo_types', 'loyalty', 'life_modifier', 'hand_modifier',\n",
    "             'color_indicator', 'content_warning', 'cmc', 'keywords', 'flavor_text', 'edhrec_rank']\n",
    "\n",
    "card_text = card_text.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d61268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "\n",
    "# fill NaNs\n",
    "card_text['oracle_text'] = card_text['oracle_text'].fillna('None')\n",
    "\n",
    "# drop useless rows\n",
    "vangard_mask = ((card_text['set_type'] == 'vanguard') |\n",
    "                (card_text['type_line'] == 'Vanguard') |\n",
    "                (card_text['set_name'].str.contains('Vanguard')))\n",
    "card_text.drop(card_text[vangard_mask].index, inplace = True)\n",
    "card_text.drop(card_text[card_text['type_line'].str.contains('Emblem')].index, inplace = True)\n",
    "card_text.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# emliminate extraneous characters\n",
    "unwanted_text = \"[.,!?()•—\\\\:;|]\"\n",
    "card_text['oracle_text'] = card_text['oracle_text'].map(lambda x: re.sub(unwanted_text, '', x))\n",
    "\n",
    "# remove all references of a card's name from it's rules text\n",
    "card_text['Rules_Text'] = card_text[['name', 'oracle_text']].apply(lambda x: \n",
    "                                                                     x['oracle_text'].replace(x['name'], 'This_Card')\n",
    "                                                                     if x['name'] in x['oracle_text']\n",
    "                                                                     else x['oracle_text'],\n",
    "                                                                     axis = 1)\n",
    "\n",
    "# set rules_text to lower case\n",
    "card_text['Rules_Text'] = card_text['Rules_Text'].str.lower()\n",
    "\n",
    "# create new dataframe with which to work\n",
    "# ct = card_text['Rules_Text'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04795ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize whitespace tokenizer\n",
    "# whitespace_tokenizer = RegexpTokenizer(\"\\s+\", gaps = True)\n",
    "\n",
    "# # make new column for whitespace tokenizer\n",
    "# ct['no_space_tokens'] = ct['Rules_Text'].apply(lambda x: whitespace_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49615833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load english library with spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# # set function to get spacy tokens\n",
    "# def spacy_on_list(x):\n",
    "#     spacy_list = [nlp(element) for element in x]\n",
    "#     return spacy_list\n",
    "\n",
    "# # make new column for spacy tokens\n",
    "# ct['spacy_tokens'] = ct['no_space_tokens'].apply(lambda x: spacy_on_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save ct\n",
    "# with open('ct_df', 'wb') as f:\n",
    "#     pickle.dump(ct,f)\n",
    "    \n",
    "# load ct\n",
    "with open('ct_df', 'rb') as f:\n",
    "    ct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa5420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy fucntion to pass to custom_tfidf\n",
    "def dummy_function(doc):\n",
    "    return doc\n",
    "\n",
    "# # save spacy tokens as list\n",
    "# docs = ct['spacy_tokens'].to_list()\n",
    "\n",
    "# # save spacy tokens as series\n",
    "# doc_series = pd.Series(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc6d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set function to get lemmetized non-stop-words\n",
    "def lemmy_no_stop(x):\n",
    "    core_text = []\n",
    "    for tuple_ in x:\n",
    "        for token in tuple_:\n",
    "            core_text.append(token.lemma_)  \n",
    "    #core_text = [[token.lemma_ for token in tuple_ if token.is_stop == False] for tuple_ in x]  \n",
    "    core_text = [ele for ele in core_text if ele != []]\n",
    "    return core_text\n",
    "\n",
    "# apply fucntion to create new column in ct\n",
    "ct['core_text'] = ct['spacy_tokens'].apply(lambda x: lemmy_no_stop(x))\n",
    "\n",
    "# convert that column to a list\n",
    "core_docs = ct['core_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69bb965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize custom_tfidf from TfidfVectorizer\n",
    "custom_tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy_function, preprocessor=dummy_function, token_pattern=None)\n",
    "\n",
    "# fit transform docs to CX \n",
    "CX = custom_tfidf.fit_transform(core_docs).toarray()\n",
    "\n",
    "# create a dataframe from CX and feature_names from custom_tfidf\n",
    "custom_tfidf_df = pd.DataFrame(CX, columns=custom_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdafa731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26182, 4681)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CX = StandardScaler().fit_transform(CX)\n",
    "CX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb466e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835041270596884"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 1500)\n",
    "pca.fit(CX)\n",
    "\n",
    "def evr(array):\n",
    "    _sum = 0\n",
    "    for element in array:\n",
    "        _sum += element\n",
    "    return _sum\n",
    "\n",
    "evr(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f386e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CX = pca.transform(CX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76533f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.49738673e-03, -5.20521458e-02,  1.07023742e-01, ...,\n",
       "        -2.38738651e-04, -3.56320749e-04, -1.27740987e-04],\n",
       "       [ 2.17923249e-02, -3.86039751e-02,  2.51838506e-01, ...,\n",
       "         1.34802838e-05, -8.63747316e-04, -8.05474575e-04],\n",
       "       [-4.97221009e-02, -5.14905759e-02, -2.56600475e-01, ...,\n",
       "         8.42918915e-04, -2.10655767e-03, -2.37060332e-03],\n",
       "       ...,\n",
       "       [ 9.90173382e-01, -1.33789425e-03, -4.95280928e-02, ...,\n",
       "        -1.63327114e-07, -8.09362318e-08,  5.74114895e-08],\n",
       "       [-5.71078547e-02, -9.58915125e-02, -2.46682450e-02, ...,\n",
       "        -6.30513219e-04,  3.06803546e-04,  9.21262196e-04],\n",
       "       [ 2.11558785e-02, -2.77476184e-02,  1.89309026e-01, ...,\n",
       "         1.30968644e-04,  3.40039953e-04,  4.80229263e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e6bd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Card:\tMerfolk Looter\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Merfolk Rogue\n",
      "Text:\t\t{T} Draw a card then discard a card\n",
      "************************************************************\n",
      "************************************************************\n",
      "1.\n",
      "Similarity:\t100.0%\n",
      "Name:\t\tThe Harvester\n",
      "Mana Cost:\t\n",
      "Type:\t\tHero\n",
      "Text:\t\t{t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "2.\n",
      "Similarity:\t100.0%\n",
      "Name:\t\tThought Courier\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "3.\n",
      "Similarity:\t92.0%\n",
      "Name:\t\tReckless Scholar\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} target player draws a card then discards a card\n",
      "------------------------------------------------------------\n",
      "4.\n",
      "Similarity:\t92.0%\n",
      "Name:\t\tCephalid Looter\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Cephalid Rogue\n",
      "Text:\t\t{t} target player draws a card then discards a card\n",
      "------------------------------------------------------------\n",
      "5.\n",
      "Similarity:\t92.0%\n",
      "Name:\t\tRummaging Goblin\n",
      "Mana Cost:\t{2}{R}\n",
      "Type:\t\tCreature — Goblin Rogue\n",
      "Text:\t\t{t} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "6.\n",
      "Similarity:\t91.0%\n",
      "Name:\t\tA-Dragonborn Looter\n",
      "Mana Cost:\t{U}\n",
      "Type:\t\tCreature — Dragon Rogue\n",
      "Text:\t\t{1} {t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "7.\n",
      "Similarity:\t91.0%\n",
      "Name:\t\tDragonborn Looter\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Dragon Rogue\n",
      "Text:\t\t{1} {t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "8.\n",
      "Similarity:\t91.0%\n",
      "Name:\t\tFacet Reader\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{1} {t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "9.\n",
      "Similarity:\t91.0%\n",
      "Name:\t\tJalum Tome\n",
      "Mana Cost:\t{3}\n",
      "Type:\t\tArtifact\n",
      "Text:\t\t{2} {t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "10.\n",
      "Similarity:\t90.0%\n",
      "Name:\t\tLore Broker\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Human Rogue\n",
      "Text:\t\t{t} each player draws a card then discards a card\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Local\\Temp/ipykernel_17456/2671638119.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top10['Rules_Text'] = top10['Rules_Text'].str.replace('\\n', ', ')\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe for results\n",
    "\n",
    "# card_name = \"Kess, Dissident Mage\"\n",
    "card_name = \"Merfolk Looter\"\n",
    "\n",
    "index = card_text.index[card_text['name'] == card_name]\n",
    "distances = pairwise_distances(CX[index].reshape(1,-1), CX, metric='cosine')\n",
    "\n",
    "results_df = card_text[['name', 'Rules_Text', 'color_identity', 'mana_cost', 'type_line', 'rarity', 'set_name',\n",
    "                                'set_type']]\n",
    "results_df.insert(loc = 0, column = 'distances', value = pd.Series(distances[0]))\n",
    "\n",
    "top10 = results_df[results_df['name'] != card_name]\n",
    "top10['Rules_Text'] = top10['Rules_Text'].str.replace('\\n', ', ')\n",
    "card_text['oracle_text'] = card_text['oracle_text'].str.replace('\\n', ', ')\n",
    "top10 = top10.sort_values(by = 'distances', ascending = True).head(10).reset_index(drop=True)\n",
    "\n",
    "# output results\n",
    "print(f\"Chosen Card:\\t{card_text['name'].iloc[index[0]]}\")\n",
    "print(f\"Mana Cost:\\t{card_text['mana_cost'].iloc[index[0]]}\")\n",
    "print(f\"Type:\\t\\t{card_text['type_line'].iloc[index[0]]}\")\n",
    "print(f\"Text:\\t\\t{card_text['oracle_text'].iloc[index[0]]}\\n{'*'*60}\\n{'*'*60}\")\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}.\\nSimilarity:\\t{(1-round(top10['distances'].values[i], 2))*100}%\")\n",
    "    print(f\"Name:\\t\\t{top10['name'].values[i]}\")\n",
    "    print(f\"Mana Cost:\\t{top10['mana_cost'].values[i]}\")\n",
    "    print(f\"Type:\\t\\t{top10['type_line'].values[i]}\")\n",
    "    print(f\"Text:\\t\\t{top10['Rules_Text'].values[i]}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56521d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Less than perfect matches for: Kess, Dissident Mage\n",
    "\n",
    "# Karador, Ghost Chieftain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
