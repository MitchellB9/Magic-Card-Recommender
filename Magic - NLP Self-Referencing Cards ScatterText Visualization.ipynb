{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e6b8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "from spacy import displacy\n",
    "import scattertext as st\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2facee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "card_text = pd.read_json('oracle-cards-20220819210331.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39c91731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 69 unnecessary columns\n",
    "\n",
    "drop_cols = ['object', 'id', 'oracle_id', 'multiverse_ids', 'mtgo_id', 'mtgo_foil_id', 'tcgplayer_id','cardmarket_id', 'lang', \n",
    "             'released_at', 'uri', 'scryfall_uri', 'layout', 'highres_image', 'image_status', 'image_uris', 'colors',\n",
    "             'legalities', 'games', 'reserved', 'foil', 'nonfoil', 'finishes', 'oversized', 'promo', 'reprint', 'variation',\n",
    "             'set_id', 'set', 'set_uri', 'set_search_uri', 'scryfall_set_uri', 'rulings_uri', 'prints_search_uri',\n",
    "             'collector_number', 'digital', 'card_back_id', 'artist', 'artist_ids', 'illustration_id', 'border_color', 'frame',\n",
    "             'full_art', 'textless', 'booster', 'story_spotlight', 'prices', 'related_uris', 'security_stamp', 'preview',\n",
    "             'power', 'toughness', 'penny_rank', 'arena_id', 'watermark', 'produced_mana', 'all_parts', 'card_faces',\n",
    "             'frame_effects', 'tcgplayer_etched_id', 'promo_types', 'loyalty', 'life_modifier', 'hand_modifier',\n",
    "             'color_indicator', 'content_warning', 'cmc', 'keywords', 'flavor_text', 'edhrec_rank']\n",
    "\n",
    "card_text = card_text.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89d61268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "\n",
    "# fill NaNs\n",
    "card_text['oracle_text'] = card_text['oracle_text'].fillna('None')\n",
    "\n",
    "# drop useless rows\n",
    "vangard_mask = ((card_text['set_type'] == 'vanguard') |\n",
    "                (card_text['type_line'] == 'Vanguard') |\n",
    "                (card_text['set_name'].str.contains('Vanguard')))\n",
    "card_text.drop(card_text[vangard_mask].index, inplace = True)\n",
    "card_text.drop(card_text[card_text['type_line'].str.contains('Emblem')].index, inplace = True)\n",
    "card_text.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# emliminate extraneous characters\n",
    "unwanted_text = \"[.,!?()•—\\\\:;|]\"\n",
    "card_text['oracle_text'] = card_text['oracle_text'].map(lambda x: re.sub(unwanted_text, '', x))\n",
    "\n",
    "# remove all references of a card's name from it's rules text\n",
    "card_text['Rules_Text'] = card_text[['name', 'oracle_text']].apply(lambda x: \n",
    "                                                                     x['oracle_text'].replace(x['name'], 'This_Card')\n",
    "                                                                     if x['name'] in x['oracle_text']\n",
    "                                                                     else x['oracle_text'],\n",
    "                                                                     axis = 1)\n",
    "\n",
    "# set rules_text to lower case\n",
    "card_text['Rules_Text'] = card_text['Rules_Text'].str.lower()\n",
    "\n",
    "# create new dataframe with which to work\n",
    "# ct = card_text['Rules_Text'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04795ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize whitespace tokenizer\n",
    "# whitespace_tokenizer = RegexpTokenizer(\"\\s+\", gaps = True)\n",
    "\n",
    "# # make new column for whitespace tokenizer\n",
    "# ct['no_space_tokens'] = ct['Rules_Text'].apply(lambda x: whitespace_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "772bee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49615833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load english library with spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# # set function to get spacy tokens\n",
    "# def spacy_on_list(x):\n",
    "#     spacy_list = [nlp(element) for element in x]\n",
    "#     return spacy_list\n",
    "\n",
    "# # make new column for spacy tokens\n",
    "# ct['spacy_tokens'] = ct['no_space_tokens'].apply(lambda x: spacy_on_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef4c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save ct\n",
    "# with open('ct_df', 'wb') as f:\n",
    "#     pickle.dump(ct,f)\n",
    "    \n",
    "# load ct\n",
    "with open('ct_df', 'rb') as f:\n",
    "    ct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aa5420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy fucntion to pass to custom_tfidf\n",
    "def dummy_function(doc):\n",
    "    return doc\n",
    "\n",
    "# # save spacy tokens as list\n",
    "# docs = ct['spacy_tokens'].to_list()\n",
    "\n",
    "# # save spacy tokens as series\n",
    "# doc_series = pd.Series(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1cc6d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set function to get lemmetized non-stop-words\n",
    "def lemmy_no_stop(x):\n",
    "    core_text = []\n",
    "    for tuple_ in x:\n",
    "        for token in tuple_:\n",
    "            core_text.append(token.lemma_)  \n",
    "    #core_text = [[token.lemma_ for token in tuple_ if token.is_stop == False] for tuple_ in x]  \n",
    "    core_text = [ele for ele in core_text if ele != []]\n",
    "    return core_text\n",
    "\n",
    "# apply fucntion to create new column in ct\n",
    "ct['core_text'] = ct['spacy_tokens'].apply(lambda x: lemmy_no_stop(x))\n",
    "\n",
    "# convert that column to a list\n",
    "core_docs = ct['core_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a135ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_text['Core_Text'] = ct['core_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing cards that don't have rules text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb2ac4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_text['Core_Text'] = card_text['Core_Text'].apply(lambda x: np.nan if x == [] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd005dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_text.dropna(subset=['Core_Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "396d943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25604"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(card_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731e99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "198afe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use scattertext, need to categorize data into two categories\n",
    "# Since we are evaluating Kess, the two categories will be if it contains the Kess effect and if it does not\n",
    "# Kess effect: Cast an instant or sorcery spell from your graveyard.\n",
    "#              If a spell cast this way would be put into your graveyard exile it instead.\n",
    "# kessLike_condition = ['graveyard', 'exile', 'instead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee30877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# card_text['Kess_Effect'] = card_text['Core_Text'].apply(lambda x: all(elem in x for elem in kessLike_condition)).map({True: \"KessLike\", False: \"Not_KessLike\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f50d9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_ref_condition = 'this_card'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "139e315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_ref_test(x):\n",
    "    if self_ref_condition in x:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ec3ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_text['Self_Ref'] = card_text['Core_Text'].apply(lambda x: self_ref_test(x)).map({True: \"Refs_Self\", False: \"No_Ref_Self\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be692316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325\n"
     ]
    }
   ],
   "source": [
    "# Seeing how many cards reference themselves\n",
    "refCount = 0\n",
    "for x in card_text['Self_Ref']:\n",
    "    if x == 'Refs_Self':\n",
    "        refCount += 1\n",
    "print(refCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fb9ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Seeing how many cards don't have rules text\n",
    "emptyCount = 0\n",
    "for x in card_text['Core_Text']:\n",
    "    if x == []:\n",
    "        emptyCount +=1\n",
    "print(emptyCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "20ca159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the ScatterText corpus:\n",
    "corpus = st.CorpusFromPandas(\n",
    "    card_text,\n",
    "    category_col = 'Self_Ref',\n",
    "    text_col = 'Rules_Text',\n",
    "    nlp=nlp\n",
    ").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dde867fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25604"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(card_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d6d28b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Refs_Self', 'No_Ref_Self']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "211d0a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25604"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(card_text['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b6bbb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling:\n",
    "assert type(corpus) == st.CorpusDF, \"Be sure to create your corpus from the dataframe provided.  It should be a scattertext CorpusDF object.\"\n",
    "assert corpus.get_num_docs() == len(card_text), \"Your corpus should be constructed from card_text and should have the same number of documents as card_text.\"\n",
    "assert corpus.get_categories() == ['Refs_Self', 'No_Ref_Self'], \"The categories of your corpus should be 'Refs_Self' and 'No_Ref_Self'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fe4bc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ScatterText html:\n",
    "html = st.produce_scattertext_explorer(\n",
    "        corpus,\n",
    "        category=\"Refs_Self\",\n",
    "        category_name='Refs_Self',\n",
    "        not_category_name='No_Ref_Self',\n",
    "        minimum_term_frequency=10,\n",
    "        pmi_threshold_coefficient=5,\n",
    "        width_in_pixels=1000,\n",
    "        metadata=card_text['name'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58158256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates an HTML document in your current Notebook directory. Find it and click on it to view the interactive plot\n",
    "open('self_reference_cards.html', 'wb').write(html.encode('utf-8'));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
