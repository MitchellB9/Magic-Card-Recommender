{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6b8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2facee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "card_text = pd.read_json('oracle-cards-20220819210331.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c91731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 69 unnecessary columns\n",
    "\n",
    "drop_cols = ['object', 'id', 'oracle_id', 'multiverse_ids', 'mtgo_id', 'mtgo_foil_id', 'tcgplayer_id','cardmarket_id', 'lang', \n",
    "             'released_at', 'uri', 'scryfall_uri', 'layout', 'highres_image', 'image_status', 'image_uris', 'colors',\n",
    "             'legalities', 'games', 'reserved', 'foil', 'nonfoil', 'finishes', 'oversized', 'promo', 'reprint', 'variation',\n",
    "             'set_id', 'set', 'set_uri', 'set_search_uri', 'scryfall_set_uri', 'rulings_uri', 'prints_search_uri',\n",
    "             'collector_number', 'digital', 'card_back_id', 'artist', 'artist_ids', 'illustration_id', 'border_color', 'frame',\n",
    "             'full_art', 'textless', 'booster', 'story_spotlight', 'prices', 'related_uris', 'security_stamp', 'preview',\n",
    "             'power', 'toughness', 'penny_rank', 'arena_id', 'watermark', 'produced_mana', 'all_parts', 'card_faces',\n",
    "             'frame_effects', 'tcgplayer_etched_id', 'promo_types', 'loyalty', 'life_modifier', 'hand_modifier',\n",
    "             'color_indicator', 'content_warning', 'cmc', 'keywords', 'flavor_text', 'edhrec_rank']\n",
    "\n",
    "card_text = card_text.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d61268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "\n",
    "# fill NaNs\n",
    "card_text['oracle_text'] = card_text['oracle_text'].fillna('None')\n",
    "\n",
    "# drop useless rows\n",
    "vangard_mask = ((card_text['set_type'] == 'vanguard') |\n",
    "                (card_text['type_line'] == 'Vanguard') |\n",
    "                (card_text['set_name'].str.contains('Vanguard')))\n",
    "card_text.drop(card_text[vangard_mask].index, inplace = True)\n",
    "card_text.drop(card_text[card_text['type_line'].str.contains('Emblem')].index, inplace = True)\n",
    "card_text.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# emliminate extraneous characters\n",
    "unwanted_text = \"[.,!?()•—\\\\:;|]\"\n",
    "card_text['oracle_text'] = card_text['oracle_text'].map(lambda x: re.sub(unwanted_text, '', x))\n",
    "\n",
    "# remove all references of a card's name from it's rules text\n",
    "card_text['Rules_Text'] = card_text[['name', 'oracle_text']].apply(lambda x: \n",
    "                                                                     x['oracle_text'].replace(x['name'], 'This_Card')\n",
    "                                                                     if x['name'] in x['oracle_text']\n",
    "                                                                     else x['oracle_text'],\n",
    "                                                                     axis = 1)\n",
    "\n",
    "# set rules_text to lower case\n",
    "card_text['Rules_Text'] = card_text['Rules_Text'].str.lower()\n",
    "\n",
    "# # create new dataframe with which to work\n",
    "# ct = card_text['Rules_Text'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04795ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize whitespace tokenizer\n",
    "# whitespace_tokenizer = RegexpTokenizer(\"\\s+\", gaps = True)\n",
    "\n",
    "# # make new column for whitespace tokenizer\n",
    "# ct['no_space_tokens'] = ct['Rules_Text'].apply(lambda x: whitespace_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d68e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load english library with spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# # set function to get spacy tokens\n",
    "# def spacy_on_list(x):\n",
    "#     spacy_list = [nlp(element) for element in x]\n",
    "#     return spacy_list\n",
    "\n",
    "# # make new column for spacy tokens\n",
    "# ct['spacy_tokens'] = ct['no_space_tokens'].apply(lambda x: spacy_on_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a57f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ct\n",
    "# with open('ct_df', 'wb') as f:\n",
    "#     pickle.dump(ct,f)\n",
    "    \n",
    "# load ct\n",
    "with open('ct_df', 'rb') as f:\n",
    "    ct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3cce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy fucntion to pass to custom_tfidf\n",
    "def dummy_function(doc):\n",
    "    return doc\n",
    "\n",
    "# # save spacy tokens as list\n",
    "# docs = ct['spacy_tokens'].to_list()\n",
    "\n",
    "# # save spacy tokens as series\n",
    "# doc_series = pd.Series(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd7e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set function to get lemmetized non-stop-words\n",
    "def lemmy_no_stop(x):\n",
    "    core_text = []\n",
    "    for tuple_ in x:\n",
    "        for token in tuple_:\n",
    "            core_text.append(token.lemma_)  \n",
    "    #core_text = [[token.lemma_ for token in tuple_ if token.is_stop == False] for tuple_ in x]  \n",
    "    core_text = [ele for ele in core_text if ele != []]\n",
    "    return core_text\n",
    "\n",
    "# apply fucntion to create new column in ct\n",
    "ct['core_text'] = ct['spacy_tokens'].apply(lambda x: lemmy_no_stop(x))\n",
    "\n",
    "# convert that column to a list\n",
    "core_docs = ct['core_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526d87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tfidf_2gram = TfidfVectorizer(analyzer='word', tokenizer=dummy_function,\n",
    "                                     preprocessor=dummy_function, token_pattern=None)\n",
    "CX_2gram = custom_tfidf_2gram.fit_transform(core_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9863ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26182, 4681)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CX_2gram = StandardScaler().fit_transform(CX_2gram)\n",
    "CX_2gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ba6ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448775355129494"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 150)\n",
    "pca.fit(CX_2gram)\n",
    "# pca.explained_variance_ratio_\n",
    "\n",
    "def evr (array):\n",
    "    _sum = 0\n",
    "    for element in array:\n",
    "        _sum += element\n",
    "    return _sum\n",
    "\n",
    "evr(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d0930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CX_2gram = pca.transform(CX_2gram)\n",
    "np_CX = np.array(CX_2gram)\n",
    "non_neg_CX_2gram = np_CX + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04b31e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "C:\\Users\\mitch\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "nmf_2gram = NMF(20)\n",
    "nmf_2gram = nmf_2gram.fit(non_neg_CX_2gram)\n",
    "docs_topics_2gram = nmf_2gram.transform(non_neg_CX_2gram)\n",
    "topics_terms_2gram = nmf_2gram.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afee4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_2gram_df = pd.DataFrame(docs_topics_2gram, columns = ['Topic_0', 'Topic_1', 'Topic_2', 'Topic_3', 'Topic_4', 'Topic_5',\n",
    "#                                                           'Topic_6', 'Topic_7', 'Topic_8', 'Topic_9', 'Topic_10', 'Topic_11',\n",
    "#                                                           'Topic_12', 'Topic_13', 'Topic_14', 'Topic_15', 'Topic_16',\n",
    "#                                                           'Topic_17', 'Topic_18', 'Topic_19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df47a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = card_text[['name', 'Rules_Text', 'color_identity', 'mana_cost', 'type_line', 'rarity', 'set_name',\n",
    "#                                 'set_type']]\n",
    "# topics = nmf_2gram_df.merge(results_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54d68816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppers = ['Topic_0', 'Topic_1', 'Topic_2', 'Topic_3', 'Topic_4', 'Topic_5', 'Topic_6', 'Topic_7', 'Topic_8',\n",
    "#             'Topic_9', 'Topic_19', 'Topic_11', 'Topic_12', 'Topic_13', 'Topic_14', 'Topic_15', 'Topic_16', 'Topic_17',\n",
    "#             'Topic_18']\n",
    "\n",
    "# target_topic = 'Topic_10'\n",
    "\n",
    "# # top10 = top10.sort_values(by = 'distances', ascending = True).head(10).reset_index(drop=True)\n",
    "# topic_mask = topics[target_topic] != 0\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# topics[topic_mask].drop(columns = droppers, axis = 1).sort_values(by = target_topic, ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc80f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: **garbage**\n",
    "# 1: tap for mana\n",
    "# 2: +1/+1 till end of turn\n",
    "# 3: ETB\n",
    "# 4: look at top cards of library\n",
    "# 5: enchant creature\n",
    "# 6: **garbage**\n",
    "# 7: enchant creature\n",
    "# 8: **garbage**\n",
    "# 9: reanimate\n",
    "# 10: **garbage**\n",
    "# 11: upkeep trigger\n",
    "# 12: face down\n",
    "# 13: stuff you control\n",
    "# 14: prevent damage\n",
    "# 15: bounce\n",
    "# 16: tutor\n",
    "# 17: prevent damage\n",
    "# 18: cost reduction\n",
    "# 19: discard/draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f775ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8e6bd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Card:\tMerfolk Looter\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Merfolk Rogue\n",
      "Text:\t\t{T} Draw a card then discard a card\n",
      "************************************************************\n",
      "************************************************************\n",
      "1.\n",
      "Similarity:\t100.0%\n",
      "Name:\t\tThought Courier\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "2.\n",
      "Similarity:\t100.0%\n",
      "Name:\t\tThe Harvester\n",
      "Mana Cost:\t\n",
      "Type:\t\tHero\n",
      "Text:\t\t{t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "3.\n",
      "Similarity:\t99.96000000000001%\n",
      "Name:\t\tRummaging Goblin\n",
      "Mana Cost:\t{2}{R}\n",
      "Type:\t\tCreature — Goblin Rogue\n",
      "Text:\t\t{t} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "4.\n",
      "Similarity:\t99.92999999999999%\n",
      "Name:\t\tMad Prophet\n",
      "Mana Cost:\t{3}{R}\n",
      "Type:\t\tCreature — Human Shaman\n",
      "Text:\t\thaste, {t} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "5.\n",
      "Similarity:\t99.91%\n",
      "Name:\t\tSelhoff Entomber\n",
      "Mana Cost:\t{1}{U}\n",
      "Type:\t\tCreature — Zombie\n",
      "Text:\t\t{t} discard a creature card draw a card\n",
      "------------------------------------------------------------\n",
      "6.\n",
      "Similarity:\t99.9%\n",
      "Name:\t\tKrovikan Sorcerer\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} discard a nonblack card draw a card, {t} discard a black card draw two cards then discard one of them\n",
      "------------------------------------------------------------\n",
      "7.\n",
      "Similarity:\t99.85000000000001%\n",
      "Name:\t\tBonded Fetch\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Homunculus\n",
      "Text:\t\tdefender haste, {t} draw a card then discard a card\n",
      "------------------------------------------------------------\n",
      "8.\n",
      "Similarity:\t99.83999999999999%\n",
      "Name:\t\tMental Discipline\n",
      "Mana Cost:\t{1}{U}{U}\n",
      "Type:\t\tEnchantment\n",
      "Text:\t\t{1}{u} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "9.\n",
      "Similarity:\t99.83%\n",
      "Name:\t\tOread of Mountain's Blaze\n",
      "Mana Cost:\t{1}{R}\n",
      "Type:\t\tEnchantment Creature — Nymph\n",
      "Text:\t\t{2}{r} discard a card draw a card\n",
      "------------------------------------------------------------\n",
      "10.\n",
      "Similarity:\t99.83%\n",
      "Name:\t\tReckless Scholar\n",
      "Mana Cost:\t{2}{U}\n",
      "Type:\t\tCreature — Human Wizard\n",
      "Text:\t\t{t} target player draws a card then discards a card\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Local\\Temp/ipykernel_19888/2212727556.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top10['Rules_Text'] = top10['Rules_Text'].str.replace('\\n', ', ')\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe for results\n",
    "\n",
    "# card_name = \"Kess, Dissident Mage\"\n",
    "card_name = \"Merfolk Looter\"\n",
    "\n",
    "index = card_text.index[card_text['name'] == card_name]\n",
    "distances = pairwise_distances(docs_topics_2gram[index].reshape(1,-1), docs_topics_2gram, metric='cosine')\n",
    "\n",
    "results_df = card_text[['name', 'Rules_Text', 'color_identity', 'mana_cost', 'type_line', 'rarity', 'set_name', 'set_type']]\n",
    "results_df.insert(loc = 0, column = 'distances', value = pd.Series(distances[0]))\n",
    "\n",
    "top10 = results_df[results_df['name'] != card_name]\n",
    "top10['Rules_Text'] = top10['Rules_Text'].str.replace('\\n', ', ')\n",
    "card_text['oracle_text'] = card_text['oracle_text'].str.replace('\\n', ', ')\n",
    "top10 = top10.sort_values(by = 'distances', ascending = True).head(10).reset_index(drop=True)\n",
    "\n",
    "# output results\n",
    "print(f\"Chosen Card:\\t{card_text['name'].iloc[index[0]]}\")\n",
    "print(f\"Mana Cost:\\t{card_text['mana_cost'].iloc[index[0]]}\")\n",
    "print(f\"Type:\\t\\t{card_text['type_line'].iloc[index[0]]}\")\n",
    "print(f\"Text:\\t\\t{card_text['oracle_text'].iloc[index[0]]}\\n{'*'*60}\\n{'*'*60}\")\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}.\")\n",
    "#     print(f\"Similarity:\\t{top10['distances'].values[i]}\")\n",
    "    print(f\"Similarity:\\t{round((1-top10['distances'].values[i]), 4)*100}%\")\n",
    "    print(f\"Name:\\t\\t{top10['name'].values[i]}\")\n",
    "    print(f\"Mana Cost:\\t{top10['mana_cost'].values[i]}\")\n",
    "    print(f\"Type:\\t\\t{top10['type_line'].values[i]}\")\n",
    "    print(f\"Text:\\t\\t{top10['Rules_Text'].values[i]}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ce2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Less than perfect matches for: Kess, Dissident Mage\n",
    "\n",
    "# Fury of the Horde\n",
    "# Into the Fray\n",
    "# Dead Revels\n",
    "# Omniscience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0cacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_2gram_10_df = pd.DataFrame(docs_topics_2gram, columns = ['ETB',\n",
    "#                                                              'until_end_of_turn',\n",
    "#                                                              'burn',\n",
    "#                                                              'scry_effect',\n",
    "#                                                              '+1/+1_counters',\n",
    "#                                                              'unblockable',\n",
    "#                                                              'reanimation',\n",
    "#                                                              'upkeep_trigger',\n",
    "#                                                              'card_advantage',\n",
    "#                                                              'enchant_creature',\n",
    "#                                                              'face_down',\n",
    "#                                                              'mana_ability',\n",
    "#                                                              'buff_creatures',\n",
    "#                                                              'prevent_damage',\n",
    "#                                                              'tutor',\n",
    "#                                                              'sacrifice_cost',\n",
    "#                                                              'destroy_target',\n",
    "#                                                              'stats_equal_to_X',\n",
    "#                                                              'bounce',\n",
    "#                                                              'lifegain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporate topic ratio per output\n",
    "# find size of each topic\n",
    "# streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
